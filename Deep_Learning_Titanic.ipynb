{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZC-I332znNa",
        "colab_type": "text"
      },
      "source": [
        "# Implemenation Deep Learning for Dataset Titanic "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-SjzSOVzMtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Some librarys\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2_ev2uT0zbo",
        "colab_type": "text"
      },
      "source": [
        "### Mount My Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtGrjhiR0yZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6311b9a-42a5-4d1c-cdef-063f697db448"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMUvRqEU0Z9t",
        "colab_type": "text"
      },
      "source": [
        "###  Colleting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_kZYitv0ZMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c27a7a72-397f-4e61-ef7e-b97465ec7e37"
      },
      "source": [
        "X_train = pd.read_csv(r'/content/drive/My Drive/Titanic/train.csv')\n",
        "X_test_truth = pd.read_csv(r'/content/drive/My Drive/Titanic/test.csv')\n",
        "X_train.head(5)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIZECF6n18_b",
        "colab_type": "text"
      },
      "source": [
        "### Data Wrabling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkqx0xDX1k2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "561ed14d-8e50-4f9c-c526-f8014a76be55"
      },
      "source": [
        "# Delete some columns that is not concerned\n",
        "def drop_not_concerned_columns(data, columns):\n",
        "    return data.drop(columns, axis=1)\n",
        "\n",
        "columns = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked']\n",
        "X_train = drop_not_concerned_columns(X_train, columns)\n",
        "X_test_truth = drop_not_concerned_columns(X_test_truth, columns)\n",
        "X_train.head(5)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare\n",
              "0         0       3    male  22.0      1      0   7.2500\n",
              "1         1       1  female  38.0      1      0  71.2833\n",
              "2         1       3  female  26.0      0      0   7.9250\n",
              "3         1       1  female  35.0      1      0  53.1000\n",
              "4         0       3    male  35.0      0      0   8.0500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8vg3Ody3zB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5f879ef6-3536-4ce3-a0e6-5c24d9c213b3"
      },
      "source": [
        "nan_columns = ['Age', 'SibSp', 'Parch']\n",
        "print(len(X_train))\n",
        "X_train = X_train.dropna()\n",
        "X_test_truth = X_test_truth.dropna()\n",
        "print(len(X_train))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "891\n",
            "714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMLj_X-i5ikV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "83a68297-ca47-4acc-b72d-ca0e571a055a"
      },
      "source": [
        "#normalize \n",
        "def dummy_data(data, columns):\n",
        "    for column in columns:\n",
        "        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
        "        data = data.drop(column, axis=1)\n",
        "        \n",
        "    return data\n",
        "\n",
        "dum_columns = ['Pclass']\n",
        "X_train = dummy_data(X_train, dum_columns)\n",
        "X_test_truth = dummy_data(X_test_truth, dum_columns)\n",
        "X_train.head(5)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived     Sex   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3\n",
              "0         0    male  22.0      1      0   7.2500         0         0         1\n",
              "1         1  female  38.0      1      0  71.2833         1         0         0\n",
              "2         1  female  26.0      0      0   7.9250         0         0         1\n",
              "3         1  female  35.0      1      0  53.1000         1         0         0\n",
              "4         0    male  35.0      0      0   8.0500         0         0         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1IftpLb6miO",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOaEdsNy6eO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ad48fbcb-57cf-4fcd-9c51-4a6a38cbf248"
      },
      "source": [
        "# Transforming Sex to int and Normalize Age\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "def sex_int(data):\n",
        "    le = LabelEncoder()\n",
        "    le.fit(['male', 'female'])\n",
        "    data['Sex'] = le.transform(data['Sex'])\n",
        "    return data\n",
        "\n",
        "def normalize_age(data):\n",
        "    ss = StandardScaler()\n",
        "    data['Age'] = ss.fit_transform(data['Age'].values.reshape(-1, 1))\n",
        "    return data\n",
        "\n",
        "X_train = sex_int(X_train)\n",
        "X_train = normalize_age(X_train)\n",
        "X_test_truth = sex_int(X_test_truth)\n",
        "X_test_truth = normalize_age(X_test_truth)\n",
        "\n",
        "X_train.head(5)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.530377</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.571831</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.254825</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.365167</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.365167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Sex       Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3\n",
              "0         0    1 -0.530377      1      0   7.2500         0         0         1\n",
              "1         1    0  0.571831      1      0  71.2833         1         0         0\n",
              "2         1    0 -0.254825      0      0   7.9250         0         0         1\n",
              "3         1    0  0.365167      1      0  53.1000         1         0         0\n",
              "4         0    1  0.365167      0      0   8.0500         0         0         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewlS9HnFEsDu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "62262097-65af-4ee7-b88b-ff3309c737ca"
      },
      "source": [
        "def split_valid_test_data(data, fraction=0.8):\n",
        "    data_y = data[\"Survived\"]\n",
        "    data_x = data.drop([\"Survived\"], axis=1)\n",
        "\n",
        "    train_valid_split_idx = int(len(data_x) * fraction)\n",
        "    train_x = data_x[:train_valid_split_idx]\n",
        "    train_y = data_y[:train_valid_split_idx]\n",
        "\n",
        "    valid_test_split_idx = (len(data_x) - train_valid_split_idx) // 2\n",
        "    test_x = data_x[train_valid_split_idx + valid_test_split_idx:]\n",
        "    test_y = data_y[train_valid_split_idx + valid_test_split_idx:]\n",
        "\n",
        "    return train_x.values, train_y.values.reshape(-1, 1), test_x.values, test_y.values.reshape(-1, 1)\n",
        "\n",
        "X_train, y_train, X_test, y_test = split_valid_test_data(X_train)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)\n",
        "\n",
        "print(\"X_train:{}\".format(X_train.shape))\n",
        "print(\"train_y:{}\".format(y_train.shape))\n",
        "\n",
        "print(\"X_val:{}\".format(X_val.shape))\n",
        "print(\"y_val:{}\".format(y_val.shape))\n",
        "\n",
        "print(\"X_test:{}\".format(X_test.shape))\n",
        "print(\"y_test:{}\".format(y_test.shape))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:(428, 8)\n",
            "train_y:(428, 1)\n",
            "X_val:(143, 8)\n",
            "y_val:(143, 1)\n",
            "X_test:(72, 8)\n",
            "y_test:(72, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCzbMCmkICJy",
        "colab_type": "text"
      },
      "source": [
        "### Train & Test and Accuracy Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5xvfR2fWzmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.utils import np_utils\n",
        "\n",
        "# print(y_train.shape)\n",
        "# y_train = np_utils.to_categorical(y_train)\n",
        "# y_val = np_utils.to_categorical(y_val)\n",
        "# y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI1UvGvcGxtp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b6f4537-c80c-444f-e598-40dab9a1f5a0"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import RMSprop, Adam, SGD\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(512, input_dim=X_train.shape[1]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, input_dim=512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, input_dim=128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "model.add(Dense(64, input_dim=128))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.add((Dense(1, input_dim=64)))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "sgd = Adam(lr=0.01, beta_1=0.9)\n",
        "model.compile(optimizer = sgd,\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(x=X_train, y=y_train, batch_size=512, epochs=200, verbose=1, \n",
        "          validation_data=(X_val, y_val))\n"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 428 samples, validate on 143 samples\n",
            "Epoch 1/200\n",
            "428/428 [==============================] - 11s 26ms/step - loss: 2.1573 - acc: 0.4977 - val_loss: 2.1989 - val_acc: 0.4196\n",
            "Epoch 2/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 3.0973 - acc: 0.3972 - val_loss: 2.6851 - val_acc: 0.5804\n",
            "Epoch 3/200\n",
            "428/428 [==============================] - 0s 27us/step - loss: 2.7702 - acc: 0.5561 - val_loss: 1.0847 - val_acc: 0.5804\n",
            "Epoch 4/200\n",
            "428/428 [==============================] - 0s 29us/step - loss: 1.8439 - acc: 0.5607 - val_loss: 0.8737 - val_acc: 0.4196\n",
            "Epoch 5/200\n",
            "428/428 [==============================] - 0s 25us/step - loss: 1.5510 - acc: 0.4790 - val_loss: 0.7304 - val_acc: 0.5734\n",
            "Epoch 6/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 1.2924 - acc: 0.4790 - val_loss: 0.6497 - val_acc: 0.6853\n",
            "Epoch 7/200\n",
            "428/428 [==============================] - 0s 25us/step - loss: 1.1817 - acc: 0.5210 - val_loss: 0.7403 - val_acc: 0.5804\n",
            "Epoch 8/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.9090 - acc: 0.5794 - val_loss: 0.7733 - val_acc: 0.5804\n",
            "Epoch 9/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.9426 - acc: 0.6028 - val_loss: 0.6680 - val_acc: 0.5874\n",
            "Epoch 10/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.8704 - acc: 0.6168 - val_loss: 0.6397 - val_acc: 0.6713\n",
            "Epoch 11/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.8178 - acc: 0.5911 - val_loss: 0.6356 - val_acc: 0.6783\n",
            "Epoch 12/200\n",
            "428/428 [==============================] - 0s 32us/step - loss: 0.7788 - acc: 0.6005 - val_loss: 0.6419 - val_acc: 0.6573\n",
            "Epoch 13/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.7118 - acc: 0.5958 - val_loss: 0.6607 - val_acc: 0.5944\n",
            "Epoch 14/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.6928 - acc: 0.6075 - val_loss: 0.6775 - val_acc: 0.5804\n",
            "Epoch 15/200\n",
            "428/428 [==============================] - 0s 27us/step - loss: 0.6779 - acc: 0.6238 - val_loss: 0.6716 - val_acc: 0.5874\n",
            "Epoch 16/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.6967 - acc: 0.5818 - val_loss: 0.6667 - val_acc: 0.5804\n",
            "Epoch 17/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.6773 - acc: 0.6051 - val_loss: 0.6737 - val_acc: 0.5874\n",
            "Epoch 18/200\n",
            "428/428 [==============================] - 0s 42us/step - loss: 0.6720 - acc: 0.6051 - val_loss: 0.6806 - val_acc: 0.5804\n",
            "Epoch 19/200\n",
            "428/428 [==============================] - 0s 54us/step - loss: 0.6653 - acc: 0.6028 - val_loss: 0.6843 - val_acc: 0.5804\n",
            "Epoch 20/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.6720 - acc: 0.6051 - val_loss: 0.6829 - val_acc: 0.5804\n",
            "Epoch 21/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.6739 - acc: 0.6075 - val_loss: 0.6852 - val_acc: 0.5804\n",
            "Epoch 22/200\n",
            "428/428 [==============================] - 0s 40us/step - loss: 0.6685 - acc: 0.6238 - val_loss: 0.6870 - val_acc: 0.5804\n",
            "Epoch 23/200\n",
            "428/428 [==============================] - 0s 41us/step - loss: 0.6885 - acc: 0.6051 - val_loss: 0.6873 - val_acc: 0.5804\n",
            "Epoch 24/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.6785 - acc: 0.6145 - val_loss: 0.6776 - val_acc: 0.5804\n",
            "Epoch 25/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.6801 - acc: 0.5935 - val_loss: 0.6751 - val_acc: 0.5874\n",
            "Epoch 26/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.6805 - acc: 0.6075 - val_loss: 0.6666 - val_acc: 0.5944\n",
            "Epoch 27/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.6719 - acc: 0.5958 - val_loss: 0.6701 - val_acc: 0.5874\n",
            "Epoch 28/200\n",
            "428/428 [==============================] - 0s 29us/step - loss: 0.6711 - acc: 0.6028 - val_loss: 0.6659 - val_acc: 0.5944\n",
            "Epoch 29/200\n",
            "428/428 [==============================] - 0s 41us/step - loss: 0.6585 - acc: 0.6379 - val_loss: 0.6550 - val_acc: 0.6154\n",
            "Epoch 30/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.6656 - acc: 0.6121 - val_loss: 0.6405 - val_acc: 0.6503\n",
            "Epoch 31/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.6461 - acc: 0.6379 - val_loss: 0.6320 - val_acc: 0.6713\n",
            "Epoch 32/200\n",
            "428/428 [==============================] - 0s 25us/step - loss: 0.6817 - acc: 0.6332 - val_loss: 0.6319 - val_acc: 0.6713\n",
            "Epoch 33/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.7294 - acc: 0.6121 - val_loss: 0.6384 - val_acc: 0.6643\n",
            "Epoch 34/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.6639 - acc: 0.6262 - val_loss: 0.6470 - val_acc: 0.6154\n",
            "Epoch 35/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.6467 - acc: 0.6449 - val_loss: 0.6522 - val_acc: 0.6224\n",
            "Epoch 36/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.6877 - acc: 0.6332 - val_loss: 0.6522 - val_acc: 0.6224\n",
            "Epoch 37/200\n",
            "428/428 [==============================] - 0s 42us/step - loss: 0.6729 - acc: 0.6075 - val_loss: 0.6604 - val_acc: 0.5944\n",
            "Epoch 38/200\n",
            "428/428 [==============================] - 0s 48us/step - loss: 0.6704 - acc: 0.6215 - val_loss: 0.6770 - val_acc: 0.5874\n",
            "Epoch 39/200\n",
            "428/428 [==============================] - 0s 39us/step - loss: 0.6866 - acc: 0.5981 - val_loss: 0.6851 - val_acc: 0.5804\n",
            "Epoch 40/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.6948 - acc: 0.6145 - val_loss: 0.6861 - val_acc: 0.5804\n",
            "Epoch 41/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.6803 - acc: 0.5935 - val_loss: 0.6797 - val_acc: 0.5804\n",
            "Epoch 42/200\n",
            "428/428 [==============================] - 0s 48us/step - loss: 0.6661 - acc: 0.6121 - val_loss: 0.6748 - val_acc: 0.5874\n",
            "Epoch 43/200\n",
            "428/428 [==============================] - 0s 30us/step - loss: 0.6721 - acc: 0.6028 - val_loss: 0.6683 - val_acc: 0.5874\n",
            "Epoch 44/200\n",
            "428/428 [==============================] - 0s 39us/step - loss: 0.6627 - acc: 0.6168 - val_loss: 0.6603 - val_acc: 0.5944\n",
            "Epoch 45/200\n",
            "428/428 [==============================] - 0s 40us/step - loss: 0.6645 - acc: 0.6215 - val_loss: 0.6525 - val_acc: 0.6154\n",
            "Epoch 46/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.6755 - acc: 0.6075 - val_loss: 0.6489 - val_acc: 0.6224\n",
            "Epoch 47/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.6712 - acc: 0.6192 - val_loss: 0.6490 - val_acc: 0.6224\n",
            "Epoch 48/200\n",
            "428/428 [==============================] - 0s 44us/step - loss: 0.6699 - acc: 0.5888 - val_loss: 0.6522 - val_acc: 0.5944\n",
            "Epoch 49/200\n",
            "428/428 [==============================] - 0s 34us/step - loss: 0.6608 - acc: 0.6121 - val_loss: 0.6525 - val_acc: 0.5944\n",
            "Epoch 50/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.6663 - acc: 0.5911 - val_loss: 0.6521 - val_acc: 0.5944\n",
            "Epoch 51/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.6471 - acc: 0.6379 - val_loss: 0.6482 - val_acc: 0.5944\n",
            "Epoch 52/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.6457 - acc: 0.6121 - val_loss: 0.6399 - val_acc: 0.6014\n",
            "Epoch 53/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.6361 - acc: 0.6355 - val_loss: 0.6239 - val_acc: 0.6154\n",
            "Epoch 54/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.6328 - acc: 0.6285 - val_loss: 0.6094 - val_acc: 0.6503\n",
            "Epoch 55/200\n",
            "428/428 [==============================] - 0s 29us/step - loss: 0.6221 - acc: 0.6285 - val_loss: 0.5912 - val_acc: 0.6783\n",
            "Epoch 56/200\n",
            "428/428 [==============================] - 0s 39us/step - loss: 0.6060 - acc: 0.6472 - val_loss: 0.5815 - val_acc: 0.6713\n",
            "Epoch 57/200\n",
            "428/428 [==============================] - 0s 39us/step - loss: 0.6649 - acc: 0.6706 - val_loss: 0.5769 - val_acc: 0.6993\n",
            "Epoch 58/200\n",
            "428/428 [==============================] - 0s 41us/step - loss: 0.6352 - acc: 0.6519 - val_loss: 0.5765 - val_acc: 0.7063\n",
            "Epoch 59/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.6285 - acc: 0.6799 - val_loss: 0.5795 - val_acc: 0.7063\n",
            "Epoch 60/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.6021 - acc: 0.6752 - val_loss: 0.5845 - val_acc: 0.7133\n",
            "Epoch 61/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.6252 - acc: 0.6472 - val_loss: 0.5894 - val_acc: 0.6783\n",
            "Epoch 62/200\n",
            "428/428 [==============================] - 0s 40us/step - loss: 0.5961 - acc: 0.6799 - val_loss: 0.5949 - val_acc: 0.6434\n",
            "Epoch 63/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.6404 - acc: 0.6495 - val_loss: 0.6010 - val_acc: 0.6434\n",
            "Epoch 64/200\n",
            "428/428 [==============================] - 0s 34us/step - loss: 0.6383 - acc: 0.6379 - val_loss: 0.6035 - val_acc: 0.6224\n",
            "Epoch 65/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.6310 - acc: 0.6379 - val_loss: 0.6022 - val_acc: 0.6224\n",
            "Epoch 66/200\n",
            "428/428 [==============================] - 0s 39us/step - loss: 0.6064 - acc: 0.6285 - val_loss: 0.6014 - val_acc: 0.6224\n",
            "Epoch 67/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.6048 - acc: 0.6565 - val_loss: 0.5990 - val_acc: 0.6224\n",
            "Epoch 68/200\n",
            "428/428 [==============================] - 0s 42us/step - loss: 0.6069 - acc: 0.6379 - val_loss: 0.5944 - val_acc: 0.6224\n",
            "Epoch 69/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.6472 - acc: 0.6636 - val_loss: 0.5914 - val_acc: 0.6364\n",
            "Epoch 70/200\n",
            "428/428 [==============================] - 0s 40us/step - loss: 0.6221 - acc: 0.6332 - val_loss: 0.5941 - val_acc: 0.6434\n",
            "Epoch 71/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.5919 - acc: 0.6682 - val_loss: 0.5904 - val_acc: 0.6853\n",
            "Epoch 72/200\n",
            "428/428 [==============================] - 0s 29us/step - loss: 0.6085 - acc: 0.6332 - val_loss: 0.5873 - val_acc: 0.6993\n",
            "Epoch 73/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.6101 - acc: 0.6846 - val_loss: 0.5855 - val_acc: 0.7203\n",
            "Epoch 74/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.5994 - acc: 0.6939 - val_loss: 0.5779 - val_acc: 0.7483\n",
            "Epoch 75/200\n",
            "428/428 [==============================] - 0s 43us/step - loss: 0.6041 - acc: 0.6963 - val_loss: 0.5689 - val_acc: 0.7552\n",
            "Epoch 76/200\n",
            "428/428 [==============================] - 0s 46us/step - loss: 0.6134 - acc: 0.7126 - val_loss: 0.5616 - val_acc: 0.7483\n",
            "Epoch 77/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.5792 - acc: 0.7196 - val_loss: 0.5516 - val_acc: 0.7483\n",
            "Epoch 78/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.5735 - acc: 0.7336 - val_loss: 0.5449 - val_acc: 0.7552\n",
            "Epoch 79/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.5834 - acc: 0.7336 - val_loss: 0.5441 - val_acc: 0.7552\n",
            "Epoch 80/200\n",
            "428/428 [==============================] - 0s 34us/step - loss: 0.6047 - acc: 0.7243 - val_loss: 0.5438 - val_acc: 0.7692\n",
            "Epoch 81/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.5623 - acc: 0.7430 - val_loss: 0.5469 - val_acc: 0.7622\n",
            "Epoch 82/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5632 - acc: 0.7313 - val_loss: 0.5492 - val_acc: 0.7552\n",
            "Epoch 83/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.5546 - acc: 0.7523 - val_loss: 0.5471 - val_acc: 0.7762\n",
            "Epoch 84/200\n",
            "428/428 [==============================] - 0s 27us/step - loss: 0.5793 - acc: 0.7150 - val_loss: 0.5411 - val_acc: 0.7762\n",
            "Epoch 85/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.5321 - acc: 0.7734 - val_loss: 0.5352 - val_acc: 0.7832\n",
            "Epoch 86/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.5773 - acc: 0.7523 - val_loss: 0.5338 - val_acc: 0.7692\n",
            "Epoch 87/200\n",
            "428/428 [==============================] - 0s 30us/step - loss: 0.5446 - acc: 0.7243 - val_loss: 0.5309 - val_acc: 0.7832\n",
            "Epoch 88/200\n",
            "428/428 [==============================] - 0s 30us/step - loss: 0.5418 - acc: 0.7407 - val_loss: 0.5255 - val_acc: 0.7832\n",
            "Epoch 89/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.5922 - acc: 0.7407 - val_loss: 0.5208 - val_acc: 0.7692\n",
            "Epoch 90/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5538 - acc: 0.7850 - val_loss: 0.5187 - val_acc: 0.7762\n",
            "Epoch 91/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5701 - acc: 0.7593 - val_loss: 0.5234 - val_acc: 0.7762\n",
            "Epoch 92/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.6020 - acc: 0.7453 - val_loss: 0.5314 - val_acc: 0.7762\n",
            "Epoch 93/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.5795 - acc: 0.7640 - val_loss: 0.5369 - val_acc: 0.7902\n",
            "Epoch 94/200\n",
            "428/428 [==============================] - 0s 32us/step - loss: 0.5485 - acc: 0.7617 - val_loss: 0.5347 - val_acc: 0.7902\n",
            "Epoch 95/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.5555 - acc: 0.7617 - val_loss: 0.5281 - val_acc: 0.7832\n",
            "Epoch 96/200\n",
            "428/428 [==============================] - 0s 32us/step - loss: 0.5504 - acc: 0.7734 - val_loss: 0.5225 - val_acc: 0.7902\n",
            "Epoch 97/200\n",
            "428/428 [==============================] - 0s 26us/step - loss: 0.5414 - acc: 0.7593 - val_loss: 0.5167 - val_acc: 0.7902\n",
            "Epoch 98/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.5419 - acc: 0.7617 - val_loss: 0.5134 - val_acc: 0.7902\n",
            "Epoch 99/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5413 - acc: 0.7617 - val_loss: 0.5108 - val_acc: 0.7972\n",
            "Epoch 100/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.5315 - acc: 0.7664 - val_loss: 0.5107 - val_acc: 0.7832\n",
            "Epoch 101/200\n",
            "428/428 [==============================] - 0s 30us/step - loss: 0.5588 - acc: 0.7547 - val_loss: 0.5178 - val_acc: 0.7972\n",
            "Epoch 102/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5265 - acc: 0.7710 - val_loss: 0.5236 - val_acc: 0.7832\n",
            "Epoch 103/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.5091 - acc: 0.7804 - val_loss: 0.5265 - val_acc: 0.7762\n",
            "Epoch 104/200\n",
            "428/428 [==============================] - 0s 30us/step - loss: 0.5085 - acc: 0.7734 - val_loss: 0.5280 - val_acc: 0.7902\n",
            "Epoch 105/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.5219 - acc: 0.7640 - val_loss: 0.5286 - val_acc: 0.7832\n",
            "Epoch 106/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.5125 - acc: 0.7921 - val_loss: 0.5253 - val_acc: 0.7972\n",
            "Epoch 107/200\n",
            "428/428 [==============================] - 0s 34us/step - loss: 0.5185 - acc: 0.7664 - val_loss: 0.5204 - val_acc: 0.7902\n",
            "Epoch 108/200\n",
            "428/428 [==============================] - 0s 44us/step - loss: 0.5085 - acc: 0.7874 - val_loss: 0.5144 - val_acc: 0.7832\n",
            "Epoch 109/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.4907 - acc: 0.8084 - val_loss: 0.5094 - val_acc: 0.7832\n",
            "Epoch 110/200\n",
            "428/428 [==============================] - 0s 32us/step - loss: 0.5207 - acc: 0.7827 - val_loss: 0.5057 - val_acc: 0.7762\n",
            "Epoch 111/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5176 - acc: 0.7664 - val_loss: 0.5014 - val_acc: 0.7832\n",
            "Epoch 112/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5292 - acc: 0.7710 - val_loss: 0.5028 - val_acc: 0.7762\n",
            "Epoch 113/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.4960 - acc: 0.7874 - val_loss: 0.5078 - val_acc: 0.7902\n",
            "Epoch 114/200\n",
            "428/428 [==============================] - 0s 25us/step - loss: 0.5041 - acc: 0.7780 - val_loss: 0.5197 - val_acc: 0.7762\n",
            "Epoch 115/200\n",
            "428/428 [==============================] - 0s 25us/step - loss: 0.5217 - acc: 0.7850 - val_loss: 0.5286 - val_acc: 0.7832\n",
            "Epoch 116/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5517 - acc: 0.7640 - val_loss: 0.5434 - val_acc: 0.7832\n",
            "Epoch 117/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.5047 - acc: 0.7897 - val_loss: 0.5457 - val_acc: 0.7832\n",
            "Epoch 118/200\n",
            "428/428 [==============================] - 0s 27us/step - loss: 0.5221 - acc: 0.7757 - val_loss: 0.5422 - val_acc: 0.7692\n",
            "Epoch 119/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.5031 - acc: 0.7757 - val_loss: 0.5343 - val_acc: 0.7762\n",
            "Epoch 120/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.5441 - acc: 0.7944 - val_loss: 0.5363 - val_acc: 0.7832\n",
            "Epoch 121/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.4923 - acc: 0.7850 - val_loss: 0.5338 - val_acc: 0.7762\n",
            "Epoch 122/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.5106 - acc: 0.7430 - val_loss: 0.5329 - val_acc: 0.7762\n",
            "Epoch 123/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.5298 - acc: 0.7827 - val_loss: 0.5309 - val_acc: 0.7902\n",
            "Epoch 124/200\n",
            "428/428 [==============================] - 0s 43us/step - loss: 0.4998 - acc: 0.7991 - val_loss: 0.5260 - val_acc: 0.7972\n",
            "Epoch 125/200\n",
            "428/428 [==============================] - 0s 27us/step - loss: 0.5380 - acc: 0.7804 - val_loss: 0.5277 - val_acc: 0.7972\n",
            "Epoch 126/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.5273 - acc: 0.7780 - val_loss: 0.5273 - val_acc: 0.7762\n",
            "Epoch 127/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.5215 - acc: 0.7710 - val_loss: 0.5251 - val_acc: 0.7832\n",
            "Epoch 128/200\n",
            "428/428 [==============================] - 0s 27us/step - loss: 0.5127 - acc: 0.7921 - val_loss: 0.5234 - val_acc: 0.7902\n",
            "Epoch 129/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.5160 - acc: 0.7991 - val_loss: 0.5262 - val_acc: 0.7832\n",
            "Epoch 130/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5097 - acc: 0.7850 - val_loss: 0.5283 - val_acc: 0.7902\n",
            "Epoch 131/200\n",
            "428/428 [==============================] - 0s 27us/step - loss: 0.5036 - acc: 0.7804 - val_loss: 0.5277 - val_acc: 0.7832\n",
            "Epoch 132/200\n",
            "428/428 [==============================] - 0s 34us/step - loss: 0.5267 - acc: 0.7804 - val_loss: 0.5267 - val_acc: 0.7902\n",
            "Epoch 133/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.5248 - acc: 0.7827 - val_loss: 0.5279 - val_acc: 0.7972\n",
            "Epoch 134/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.5065 - acc: 0.7967 - val_loss: 0.5268 - val_acc: 0.7902\n",
            "Epoch 135/200\n",
            "428/428 [==============================] - 0s 40us/step - loss: 0.5030 - acc: 0.7850 - val_loss: 0.5199 - val_acc: 0.7902\n",
            "Epoch 136/200\n",
            "428/428 [==============================] - 0s 30us/step - loss: 0.4733 - acc: 0.8178 - val_loss: 0.5183 - val_acc: 0.7692\n",
            "Epoch 137/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.5053 - acc: 0.7804 - val_loss: 0.5183 - val_acc: 0.7692\n",
            "Epoch 138/200\n",
            "428/428 [==============================] - 0s 48us/step - loss: 0.5172 - acc: 0.7757 - val_loss: 0.5143 - val_acc: 0.7832\n",
            "Epoch 139/200\n",
            "428/428 [==============================] - 0s 53us/step - loss: 0.4883 - acc: 0.8014 - val_loss: 0.5139 - val_acc: 0.7832\n",
            "Epoch 140/200\n",
            "428/428 [==============================] - 0s 34us/step - loss: 0.4726 - acc: 0.7967 - val_loss: 0.5127 - val_acc: 0.7692\n",
            "Epoch 141/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.4999 - acc: 0.7897 - val_loss: 0.5147 - val_acc: 0.7692\n",
            "Epoch 142/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.5243 - acc: 0.7874 - val_loss: 0.5175 - val_acc: 0.7692\n",
            "Epoch 143/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.4923 - acc: 0.7687 - val_loss: 0.5186 - val_acc: 0.7692\n",
            "Epoch 144/200\n",
            "428/428 [==============================] - 0s 39us/step - loss: 0.4978 - acc: 0.7897 - val_loss: 0.5211 - val_acc: 0.7762\n",
            "Epoch 145/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.5021 - acc: 0.7827 - val_loss: 0.5227 - val_acc: 0.7762\n",
            "Epoch 146/200\n",
            "428/428 [==============================] - 0s 29us/step - loss: 0.4834 - acc: 0.7967 - val_loss: 0.5238 - val_acc: 0.7762\n",
            "Epoch 147/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.4897 - acc: 0.7897 - val_loss: 0.5237 - val_acc: 0.7902\n",
            "Epoch 148/200\n",
            "428/428 [==============================] - 0s 40us/step - loss: 0.4919 - acc: 0.7804 - val_loss: 0.5253 - val_acc: 0.7762\n",
            "Epoch 149/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.5004 - acc: 0.7991 - val_loss: 0.5255 - val_acc: 0.7762\n",
            "Epoch 150/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.5160 - acc: 0.7734 - val_loss: 0.5250 - val_acc: 0.7692\n",
            "Epoch 151/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.5115 - acc: 0.7757 - val_loss: 0.5202 - val_acc: 0.7622\n",
            "Epoch 152/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.4971 - acc: 0.7897 - val_loss: 0.5134 - val_acc: 0.7762\n",
            "Epoch 153/200\n",
            "428/428 [==============================] - 0s 40us/step - loss: 0.5381 - acc: 0.7944 - val_loss: 0.5187 - val_acc: 0.7832\n",
            "Epoch 154/200\n",
            "428/428 [==============================] - 0s 44us/step - loss: 0.4773 - acc: 0.7827 - val_loss: 0.5225 - val_acc: 0.7692\n",
            "Epoch 155/200\n",
            "428/428 [==============================] - 0s 44us/step - loss: 0.4812 - acc: 0.8084 - val_loss: 0.5257 - val_acc: 0.7692\n",
            "Epoch 156/200\n",
            "428/428 [==============================] - 0s 39us/step - loss: 0.4887 - acc: 0.8084 - val_loss: 0.5245 - val_acc: 0.7692\n",
            "Epoch 157/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.4619 - acc: 0.7991 - val_loss: 0.5221 - val_acc: 0.7692\n",
            "Epoch 158/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.4879 - acc: 0.8131 - val_loss: 0.5183 - val_acc: 0.7622\n",
            "Epoch 159/200\n",
            "428/428 [==============================] - 0s 34us/step - loss: 0.5073 - acc: 0.7640 - val_loss: 0.5205 - val_acc: 0.7762\n",
            "Epoch 160/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.4982 - acc: 0.7827 - val_loss: 0.5244 - val_acc: 0.7972\n",
            "Epoch 161/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.4968 - acc: 0.7944 - val_loss: 0.5276 - val_acc: 0.8112\n",
            "Epoch 162/200\n",
            "428/428 [==============================] - 0s 37us/step - loss: 0.4954 - acc: 0.7967 - val_loss: 0.5248 - val_acc: 0.8042\n",
            "Epoch 163/200\n",
            "428/428 [==============================] - 0s 29us/step - loss: 0.4992 - acc: 0.7780 - val_loss: 0.5199 - val_acc: 0.7902\n",
            "Epoch 164/200\n",
            "428/428 [==============================] - 0s 29us/step - loss: 0.4901 - acc: 0.7967 - val_loss: 0.5142 - val_acc: 0.7972\n",
            "Epoch 165/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.4676 - acc: 0.8061 - val_loss: 0.5141 - val_acc: 0.7832\n",
            "Epoch 166/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.5062 - acc: 0.7850 - val_loss: 0.5158 - val_acc: 0.7762\n",
            "Epoch 167/200\n",
            "428/428 [==============================] - 0s 28us/step - loss: 0.5178 - acc: 0.7874 - val_loss: 0.5089 - val_acc: 0.7902\n",
            "Epoch 168/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.4971 - acc: 0.7897 - val_loss: 0.5113 - val_acc: 0.7762\n",
            "Epoch 169/200\n",
            "428/428 [==============================] - 0s 29us/step - loss: 0.4914 - acc: 0.8037 - val_loss: 0.5123 - val_acc: 0.7832\n",
            "Epoch 170/200\n",
            "428/428 [==============================] - 0s 43us/step - loss: 0.4751 - acc: 0.7991 - val_loss: 0.5164 - val_acc: 0.7972\n",
            "Epoch 171/200\n",
            "428/428 [==============================] - 0s 42us/step - loss: 0.4983 - acc: 0.7967 - val_loss: 0.5231 - val_acc: 0.7902\n",
            "Epoch 172/200\n",
            "428/428 [==============================] - 0s 41us/step - loss: 0.4876 - acc: 0.7991 - val_loss: 0.5168 - val_acc: 0.7832\n",
            "Epoch 173/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.5023 - acc: 0.7804 - val_loss: 0.5173 - val_acc: 0.7902\n",
            "Epoch 174/200\n",
            "428/428 [==============================] - 0s 31us/step - loss: 0.5093 - acc: 0.7780 - val_loss: 0.5191 - val_acc: 0.7762\n",
            "Epoch 175/200\n",
            "428/428 [==============================] - 0s 29us/step - loss: 0.4775 - acc: 0.7921 - val_loss: 0.5238 - val_acc: 0.7762\n",
            "Epoch 176/200\n",
            "428/428 [==============================] - 0s 34us/step - loss: 0.4815 - acc: 0.8014 - val_loss: 0.5227 - val_acc: 0.7762\n",
            "Epoch 177/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.4485 - acc: 0.8107 - val_loss: 0.5221 - val_acc: 0.7762\n",
            "Epoch 178/200\n",
            "428/428 [==============================] - 0s 34us/step - loss: 0.4856 - acc: 0.7967 - val_loss: 0.5220 - val_acc: 0.7832\n",
            "Epoch 179/200\n",
            "428/428 [==============================] - 0s 32us/step - loss: 0.5112 - acc: 0.7874 - val_loss: 0.5250 - val_acc: 0.7762\n",
            "Epoch 180/200\n",
            "428/428 [==============================] - 0s 39us/step - loss: 0.4565 - acc: 0.8084 - val_loss: 0.5305 - val_acc: 0.7762\n",
            "Epoch 181/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.4775 - acc: 0.7897 - val_loss: 0.5282 - val_acc: 0.7762\n",
            "Epoch 182/200\n",
            "428/428 [==============================] - 0s 30us/step - loss: 0.4865 - acc: 0.8014 - val_loss: 0.5274 - val_acc: 0.7832\n",
            "Epoch 183/200\n",
            "428/428 [==============================] - 0s 24us/step - loss: 0.4742 - acc: 0.8084 - val_loss: 0.5289 - val_acc: 0.7972\n",
            "Epoch 184/200\n",
            "428/428 [==============================] - 0s 30us/step - loss: 0.4674 - acc: 0.8271 - val_loss: 0.5311 - val_acc: 0.7972\n",
            "Epoch 185/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.4676 - acc: 0.8271 - val_loss: 0.5300 - val_acc: 0.7972\n",
            "Epoch 186/200\n",
            "428/428 [==============================] - 0s 41us/step - loss: 0.4731 - acc: 0.8131 - val_loss: 0.5279 - val_acc: 0.7972\n",
            "Epoch 187/200\n",
            "428/428 [==============================] - 0s 33us/step - loss: 0.4670 - acc: 0.8154 - val_loss: 0.5245 - val_acc: 0.7902\n",
            "Epoch 188/200\n",
            "428/428 [==============================] - 0s 38us/step - loss: 0.4932 - acc: 0.7921 - val_loss: 0.5202 - val_acc: 0.8042\n",
            "Epoch 189/200\n",
            "428/428 [==============================] - 0s 43us/step - loss: 0.4868 - acc: 0.7967 - val_loss: 0.5157 - val_acc: 0.8042\n",
            "Epoch 190/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.4954 - acc: 0.7850 - val_loss: 0.5101 - val_acc: 0.7972\n",
            "Epoch 191/200\n",
            "428/428 [==============================] - 0s 35us/step - loss: 0.4741 - acc: 0.8178 - val_loss: 0.5081 - val_acc: 0.7972\n",
            "Epoch 192/200\n",
            "428/428 [==============================] - 0s 49us/step - loss: 0.4690 - acc: 0.8061 - val_loss: 0.5087 - val_acc: 0.7902\n",
            "Epoch 193/200\n",
            "428/428 [==============================] - 0s 44us/step - loss: 0.4843 - acc: 0.8084 - val_loss: 0.5174 - val_acc: 0.7762\n",
            "Epoch 194/200\n",
            "428/428 [==============================] - 0s 46us/step - loss: 0.4455 - acc: 0.8388 - val_loss: 0.5253 - val_acc: 0.7692\n",
            "Epoch 195/200\n",
            "428/428 [==============================] - 0s 39us/step - loss: 0.4573 - acc: 0.8084 - val_loss: 0.5256 - val_acc: 0.7622\n",
            "Epoch 196/200\n",
            "428/428 [==============================] - 0s 47us/step - loss: 0.4894 - acc: 0.8014 - val_loss: 0.5234 - val_acc: 0.7692\n",
            "Epoch 197/200\n",
            "428/428 [==============================] - 0s 44us/step - loss: 0.4525 - acc: 0.8271 - val_loss: 0.5272 - val_acc: 0.7832\n",
            "Epoch 198/200\n",
            "428/428 [==============================] - 0s 36us/step - loss: 0.4576 - acc: 0.8107 - val_loss: 0.5263 - val_acc: 0.7972\n",
            "Epoch 199/200\n",
            "428/428 [==============================] - 0s 32us/step - loss: 0.4731 - acc: 0.7780 - val_loss: 0.5214 - val_acc: 0.7902\n",
            "Epoch 200/200\n",
            "428/428 [==============================] - 0s 32us/step - loss: 0.5041 - acc: 0.7967 - val_loss: 0.5193 - val_acc: 0.7902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f56404bdbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVtyLk7cH8Ne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "34d3fddf-d42c-4946-a16d-a5cdac663734"
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print(\"\")\n",
        "print(\"Test loss:{0}\".format(score[0]))\n",
        "print(\"Test accuracy:{0}\".format(score[1]))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72/72 [==============================] - 0s 365us/step\n",
            "\n",
            "Test loss:0.3719721304045783\n",
            "Test accuracy:0.8611111111111112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIhCUq9KcLRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "58f1d649-d8fc-4aef-82ae-481c92255877"
      },
      "source": [
        "test_data = pd.read_csv(r'/content/drive/My Drive/Titanic/test.csv')\n",
        "test_data = test_data.drop(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'Fare', 'Name'], axis=1)\n",
        "test_data.head()"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId\n",
              "0          892\n",
              "1          893\n",
              "2          894\n",
              "3          895\n",
              "4          896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8xLzJCedYYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e06fd9b3-055e-4e3a-ce15-9454926aa8a1"
      },
      "source": [
        "predicted = model.predict(X_test_truth, verbose=1)\n",
        "print(\"Y_predicted: {}\".format(predicted[1]))\n",
        "result = list()\n",
        "for predict in predicted:\n",
        "    if predict > 0.5:\n",
        "        result.append(1)\n",
        "    else:\n",
        "        result.append(0)\n",
        "print(len(result))\n",
        "print(len(predicted))\n",
        "result = pd.DataFrame({\"Survived\":result})\n",
        "result.head(5)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "331/331 [==============================] - 0s 141us/step\n",
            "Y_predicted: [0.32393408]\n",
            "331\n",
            "331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived\n",
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ITNqdRDmb39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.to_csv('/content/drive/My Drive/Titanic/test-output.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meWC1KEbon4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}